import math
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class VulnerabilityMetrics:
    impact_score: float
    exploitability_score: float
    temporal_score: float
    environmental_score: float

class VulnerabilityAssessment:
    def __init__(self):
        # CVSS base metrics weights
        self.impact_weights = {
            'confidentiality': 0.35,
            'integrity': 0.35,
            'availability': 0.3
        }
        
        self.exploitability_weights = {
            'attack_vector': 0.25,
            'attack_complexity': 0.25,
            'privileges_required': 0.2,
            'user_interaction': 0.15,
            'scope': 0.15
        }
        
        # Temporal metrics weights
        self.temporal_weights = {
            'exploit_code_maturity': 0.4,
            'remediation_level': 0.3,
            'report_confidence': 0.3
        }
        
        # Environmental metrics weights
        self.environmental_weights = {
            'security_requirements': 0.5,
            'modified_attack_vector': 0.25,
            'asset_value': 0.25
        }
    
    def calculate_impact_score(self, metrics: Dict[str, float]) -> float:
        """Calculate impact score based on CIA triad metrics"""
        score = 0
        for metric, weight in self.impact_weights.items():
            if metric in metrics:
                score += metrics[metric] * weight
        return min(10, score * 1.2)  # Cap at 10, apply scaling factor
    
    def calculate_exploitability_score(self, metrics: Dict[str, float]) -> float:
        """Calculate exploitability score based on attack characteristics"""
        score = 0
        for metric, weight in self.exploitability_weights.items():
            if metric in metrics:
                score += metrics[metric] * weight
        return min(10, score * 1.5)  # Cap at 10, apply scaling factor
    
    def calculate_temporal_score(self, metrics: Dict[str, float]) -> float:
        """Calculate temporal score based on current exploit status"""
        score = 0
        for metric, weight in self.temporal_weights.items():
            if metric in metrics:
                score += metrics[metric] * weight
        return score
    
    def calculate_environmental_score(self, metrics: Dict[str, float]) -> float:
        """Calculate environmental score based on target environment"""
        score = 0
        for metric, weight in self.environmental_weights.items():
            if metric in metrics:
                score += metrics[metric] * weight
        return score
    
    def get_severity_level(self, metrics: VulnerabilityMetrics) -> str:
        """Determine severity level based on all metrics"""
        # Calculate weighted average of all scores
        total_score = (
            metrics.impact_score * 0.4 +
            metrics.exploitability_score * 0.3 +
            metrics.temporal_score * 0.2 +
            metrics.environmental_score * 0.1
        )
        
        # Define severity levels
        if total_score >= 9.0:
            return 'Critical'
        elif total_score >= 7.0:
            return 'High'
        elif total_score >= 4.0:
            return 'Medium'
        elif total_score >= 2.0:
            return 'Low'
        else:
            return 'Info'
    
    def assess_vulnerability(self, vuln_data: Dict) -> Dict:
        """Assess vulnerability and return enriched data with severity metrics"""
        # Extract metrics from vulnerability data
        impact_metrics = {
            'confidentiality': self._get_cia_impact(vuln_data.get('confidentiality_impact')),
            'integrity': self._get_cia_impact(vuln_data.get('integrity_impact')),
            'availability': self._get_cia_impact(vuln_data.get('availability_impact'))
        }
        
        exploitability_metrics = {
            'attack_vector': self._get_attack_vector_score(vuln_data.get('attack_vector')),
            'attack_complexity': self._get_attack_complexity_score(vuln_data.get('attack_complexity')),
            'privileges_required': self._get_privileges_score(vuln_data.get('privileges_required')),
            'user_interaction': self._get_user_interaction_score(vuln_data.get('user_interaction')),
            'scope': self._get_scope_score(vuln_data.get('scope'))
        }
        
        temporal_metrics = {
            'exploit_code_maturity': self._get_exploit_maturity_score(vuln_data.get('exploit_maturity')),
            'remediation_level': self._get_remediation_score(vuln_data.get('remediation_level')),
            'report_confidence': self._get_confidence_score(vuln_data.get('report_confidence'))
        }
        
        environmental_metrics = {
            'security_requirements': self._get_security_req_score(vuln_data.get('security_requirements')),
            'modified_attack_vector': self._get_modified_attack_vector_score(vuln_data.get('modified_attack_vector')),
            'asset_value': self._get_asset_value_score(vuln_data.get('asset_value'))
        }
        
        # Calculate scores
        metrics = VulnerabilityMetrics(
            impact_score=self.calculate_impact_score(impact_metrics),
            exploitability_score=self.calculate_exploitability_score(exploitability_metrics),
            temporal_score=self.calculate_temporal_score(temporal_metrics),
            environmental_score=self.calculate_environmental_score(environmental_metrics)
        )
        
        # Get severity level
        severity = self.get_severity_level(metrics)
        
        # Return enriched vulnerability data
        return {
            **vuln_data,
            'severity': severity,
            'impact_score': metrics.impact_score,
            'exploitability_score': metrics.exploitability_score,
            'temporal_score': metrics.temporal_score,
            'environmental_score': metrics.environmental_score,
            'total_score': (metrics.impact_score * 0.4 +
                           metrics.exploitability_score * 0.3 +
                           metrics.temporal_score * 0.2 +
                           metrics.environmental_score * 0.1)
        }
    
    def _get_cia_impact(self, impact: Optional[str]) -> float:
        """Convert CIA impact string to score"""
        impact_scores = {
            'none': 0.0,
            'low': 0.3,
            'medium': 0.6,
            'high': 1.0
        }
        return impact_scores.get(impact.lower() if impact else 'none', 0.0)
    
    def _get_attack_vector_score(self, vector: Optional[str]) -> float:
        """Convert attack vector to score"""
        vector_scores = {
            'physical': 0.2,
            'local': 0.4,
            'adjacent': 0.6,
            'network': 1.0
        }
        return vector_scores.get(vector.lower() if vector else 'local', 0.4)
    
    def _get_attack_complexity_score(self, complexity: Optional[str]) -> float:
        """Convert attack complexity to score"""
        complexity_scores = {
            'high': 0.3,
            'medium': 0.6,
            'low': 1.0
        }
        return complexity_scores.get(complexity.lower() if complexity else 'high', 0.3)
    
    def _get_privileges_score(self, privileges: Optional[str]) -> float:
        """Convert privileges required to score"""
        privilege_scores = {
            'high': 0.3,
            'low': 0.6,
            'none': 1.0
        }
        return privilege_scores.get(privileges.lower() if privileges else 'high', 0.3)
    
    def _get_user_interaction_score(self, interaction: Optional[str]) -> float:
        """Convert user interaction to score"""
        interaction_scores = {
            'required': 0.4,
            'optional': 0.7,
            'none': 1.0
        }
        return interaction_scores.get(interaction.lower() if interaction else 'required', 0.4)
    
    def _get_scope_score(self, scope: Optional[str]) -> float:
        """Convert scope to score"""
        scope_scores = {
            'unchanged': 0.5,
            'changed': 1.0
        }
        return scope_scores.get(scope.lower() if scope else 'unchanged', 0.5)
    
    def _get_exploit_maturity_score(self, maturity: Optional[str]) -> float:
        """Convert exploit maturity to score"""
        maturity_scores = {
            'unproven': 0.2,
            'poc': 0.4,
            'functional': 0.7,
            'high': 1.0
        }
        return maturity_scores.get(maturity.lower() if maturity else 'unproven', 0.2)
    
    def _get_remediation_score(self, remediation: Optional[str]) -> float:
        """Convert remediation level to score"""
        remediation_scores = {
            'official': 0.2,
            'temporary': 0.4,
            'workaround': 0.7,
            'unavailable': 1.0
        }
        return remediation_scores.get(remediation.lower() if remediation else 'unavailable', 1.0)
    
    def _get_confidence_score(self, confidence: Optional[str]) -> float:
        """Convert report confidence to score"""
        confidence_scores = {
            'unknown': 0.3,
            'reasonable': 0.6,
            'confirmed': 1.0
        }
        return confidence_scores.get(confidence.lower() if confidence else 'unknown', 0.3)
    
    def _get_security_req_score(self, requirements: Optional[str]) -> float:
        """Convert security requirements to score"""
        requirement_scores = {
            'low': 0.3,
            'medium': 0.6,
            'high': 1.0
        }
        return requirement_scores.get(requirements.lower() if requirements else 'medium', 0.6)
    
    def _get_modified_attack_vector_score(self, vector: Optional[str]) -> float:
        """Convert modified attack vector to score"""
        vector_scores = {
            'physical': 0.2,
            'local': 0.4,
            'adjacent': 0.6,
            'network': 1.0
        }
        return vector_scores.get(vector.lower() if vector else 'local', 0.4)
    
    def _get_asset_value_score(self, value: Optional[str]) -> float:
        """Convert asset value to score"""
        value_scores = {
            'low': 0.3,
            'medium': 0.6,
            'high': 1.0
        }
        return value_scores.get(value.lower() if value else 'medium', 0.6)